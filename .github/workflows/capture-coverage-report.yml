name: Capture Coverage Report

on:
  push:
    branches:
      - codex/uroflow-v2-8-integration
  schedule:
    - cron: "30 2 * * *"
  workflow_dispatch:
    inputs:
      site_id:
        description: "Optional site filter (default from repository variable CLINICAL_HUB_SITE_ID)"
        required: false
        type: string
      sync_id:
        description: "Optional sync_id filter"
        required: false
        type: string
      subject_id:
        description: "Optional subject filter"
        required: false
        type: string
      operator_id:
        description: "Optional operator filter"
        required: false
        type: string
      platform:
        description: "Optional platform filter"
        required: false
        type: choice
        options:
          - ""
          - ios
          - android
        default: ""
      capture_mode:
        description: "Optional capture mode filter"
        required: false
        type: choice
        options:
          - ""
          - water_impact
          - jet_in_air_assist
          - fallback_non_water
        default: ""
      quality_status:
        description: "Quality status filter"
        required: false
        type: choice
        options:
          - all
          - valid
          - repeat
          - reject
        default: all
      targets_config:
        description: "Path to coverage targets JSON config (repo-relative)"
        required: false
        type: string
      enforce_coverage_gates:
        description: "Fail workflow when hard gates fail"
        required: false
        type: boolean
        default: false
      db_path:
        description: "DB path in repo/runner (used only when CLINICAL_HUB_DB_URL secret is empty)"
        required: false
        type: string

concurrency:
  group: capture-coverage-report-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  generate-report:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read

    env:
      DEFAULT_SITE_ID: ${{ vars.CLINICAL_HUB_SITE_ID }}
      DEFAULT_QUALITY_STATUS: ${{ vars.CLINICAL_HUB_QUALITY_STATUS }}
      DEFAULT_TARGETS_CONFIG: ${{ vars.CLINICAL_HUB_COVERAGE_TARGETS_CONFIG }}
      DEFAULT_ENFORCE_COVERAGE_GATES: ${{ vars.CLINICAL_HUB_ENFORCE_COVERAGE_GATES }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: pyproject.toml

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install reportlab

      - name: Resolve filters
        id: filters
        shell: bash
        run: |
          set -euo pipefail

          site_id="${{ github.event.inputs.site_id }}"
          sync_id="${{ github.event.inputs.sync_id }}"
          subject_id="${{ github.event.inputs.subject_id }}"
          operator_id="${{ github.event.inputs.operator_id }}"
          platform="${{ github.event.inputs.platform }}"
          capture_mode="${{ github.event.inputs.capture_mode }}"
          quality_status="${{ github.event.inputs.quality_status }}"
          targets_config="${{ github.event.inputs.targets_config }}"
          enforce_coverage_gates="${{ github.event.inputs.enforce_coverage_gates }}"

          if [[ -z "$site_id" ]]; then
            site_id="${DEFAULT_SITE_ID:-}"
          fi
          if [[ -z "$quality_status" ]]; then
            quality_status="${DEFAULT_QUALITY_STATUS:-all}"
          fi
          if [[ -z "$targets_config" ]]; then
            targets_config="${DEFAULT_TARGETS_CONFIG:-config/coverage_targets_config.v1.json}"
          fi
          if [[ -z "$enforce_coverage_gates" ]]; then
            enforce_coverage_gates="${DEFAULT_ENFORCE_COVERAGE_GATES:-false}"
          fi
          case "${enforce_coverage_gates,,}" in
            true|1|yes|y)
              enforce_coverage_gates="true"
              ;;
            *)
              enforce_coverage_gates="false"
              ;;
          esac

          echo "site_id=$site_id" >> "$GITHUB_OUTPUT"
          echo "sync_id=$sync_id" >> "$GITHUB_OUTPUT"
          echo "subject_id=$subject_id" >> "$GITHUB_OUTPUT"
          echo "operator_id=$operator_id" >> "$GITHUB_OUTPUT"
          echo "platform=$platform" >> "$GITHUB_OUTPUT"
          echo "capture_mode=$capture_mode" >> "$GITHUB_OUTPUT"
          echo "quality_status=$quality_status" >> "$GITHUB_OUTPUT"
          echo "targets_config=$targets_config" >> "$GITHUB_OUTPUT"
          echo "enforce_coverage_gates=$enforce_coverage_gates" >> "$GITHUB_OUTPUT"

      - name: Resolve data source
        id: source
        shell: bash
        run: |
          set -euo pipefail

          if [[ -n "${{ secrets.CLINICAL_HUB_URL }}" ]]; then
            echo "Using Clinical Hub API source."
            echo "source_mode=api" >> "$GITHUB_OUTPUT"
            echo "api_base_url=${{ secrets.CLINICAL_HUB_URL }}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          if [[ -n "${{ secrets.CLINICAL_HUB_DB_URL }}" ]]; then
            echo "Downloading clinical hub DB from CLINICAL_HUB_DB_URL..."
            curl --fail --location --silent --show-error \
              "${{ secrets.CLINICAL_HUB_DB_URL }}" \
              --output /tmp/clinical_hub.db
            echo "source_mode=db" >> "$GITHUB_OUTPUT"
            echo "db_path=/tmp/clinical_hub.db" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          db_path="${{ github.event.inputs.db_path }}"
          if [[ -z "$db_path" ]]; then
            db_path="data/clinical_hub.db"
          fi

          if [[ ! -f "$db_path" ]]; then
            echo "Database file '$db_path' is missing. Building fallback fixture DB..."
            PYTHONPATH=src python - <<'PY'
            import json
            import sqlite3
            from datetime import datetime, timedelta, timezone
            from pathlib import Path

            from uroflow_mobile.clinical_hub import ensure_clinical_hub_schema

            db_path = Path("/tmp/clinical_hub_fixture.db")
            if db_path.exists():
                db_path.unlink()
            ensure_clinical_hub_schema(db_path)

            now = datetime.now(timezone.utc).replace(microsecond=0)

            with sqlite3.connect(db_path) as connection:
                for index in range(10):
                    measured_at = (now - timedelta(minutes=index)).isoformat().replace("+00:00", "Z")
                    session_id = f"SESSION-COV-{index + 1:03d}"
                    sync_id = f"SYNC-COV-{(index // 2) + 1:03d}"
                    subject_id = f"SUBJ-{index + 1:03d}"
                    platform = "ios" if index % 2 == 0 else "android"
                    quality_status = "valid"
                    if index == 8:
                        quality_status = "repeat"
                    elif index == 9:
                        quality_status = "reject"

                    paired_cursor = connection.execute(
                        """
                        INSERT INTO paired_measurements (
                            created_at,
                            measured_at,
                            session_id,
                            sync_id,
                            site_id,
                            subject_id,
                            operator_id,
                            attempt_number,
                            platform,
                            device_model,
                            app_version,
                            capture_mode,
                            app_quality_status,
                            app_quality_score,
                            app_model_id,
                            app_qmax_ml_s,
                            app_qavg_ml_s,
                            app_vvoid_ml,
                            app_flow_time_s,
                            app_tqmax_s,
                            ref_qmax_ml_s,
                            ref_qavg_ml_s,
                            ref_vvoid_ml,
                            ref_flow_time_s,
                            ref_tqmax_s,
                            ref_device_model,
                            ref_device_serial,
                            notes,
                            payload_json
                        )
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """,
                        (
                            measured_at,
                            measured_at,
                            session_id,
                            sync_id,
                            "SITE-001",
                            subject_id,
                            "OP-01",
                            1,
                            platform,
                            "fixture-device",
                            "0.1.0",
                            "water_impact",
                            quality_status,
                            92.0 - float(index),
                            "fixture-v1",
                            18.0 + float(index) * 0.2,
                            10.0 + float(index) * 0.1,
                            220.0 + float(index),
                            27.0 + float(index) * 0.1,
                            7.0 + float(index) * 0.1,
                            17.5 + float(index) * 0.2,
                            9.8 + float(index) * 0.1,
                            218.0 + float(index),
                            26.5 + float(index) * 0.1,
                            6.8 + float(index) * 0.1,
                            "ref-fixture",
                            f"REF-{index + 1:03d}",
                            "Generated fallback fixture for coverage workflow",
                            json.dumps({"fixture": True, "index": index}),
                        ),
                    )
                    paired_id = int(paired_cursor.lastrowid)

                    if index < 7 or index in {7, 8}:
                        paired_measurement_id = paired_id if index < 7 else None
                        connection.execute(
                            """
                            INSERT INTO capture_packages (
                                created_at,
                                measured_at,
                                session_id,
                                sync_id,
                                site_id,
                                subject_id,
                                operator_id,
                                attempt_number,
                                platform,
                                device_model,
                                app_version,
                                capture_mode,
                                package_type,
                                paired_measurement_id,
                                notes,
                                capture_payload_json
                            )
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """,
                            (
                                measured_at,
                                measured_at,
                                session_id,
                                sync_id,
                                "SITE-001",
                                subject_id,
                                "OP-01",
                                1,
                                platform,
                                "fixture-device",
                                "0.1.0",
                                "water_impact",
                                "capture_contract_json",
                                paired_measurement_id,
                                "Generated fallback fixture package",
                                json.dumps(
                                    {
                                        "session": {"session_id": session_id, "sync_id": sync_id},
                                        "fixture": True,
                                        "index": index,
                                    }
                                ),
                            ),
                        )
                connection.commit()

            print(f"Created fallback fixture DB at {db_path}")
            PY
            echo "source_mode=db" >> "$GITHUB_OUTPUT"
            echo "db_path=/tmp/clinical_hub_fixture.db" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "source_mode=db" >> "$GITHUB_OUTPUT"
          echo "db_path=$db_path" >> "$GITHUB_OUTPUT"

      - name: Generate coverage CSV and PDF
        id: generate
        shell: bash
        run: |
          set -euo pipefail

          report_dir="/tmp/capture-coverage-report/$(date -u +%Y%m%dT%H%M%SZ)"
          mkdir -p "$report_dir"
          csv_path="$report_dir/capture_coverage_summary.csv"
          pdf_path="$report_dir/capture_coverage_summary.pdf"
          sha_path="$csv_path.sha256"
          export TARGET_CSV="$csv_path"
          export TARGET_PDF="$pdf_path"
          export TARGET_SHA="$sha_path"

          python - <<'PY'
          import csv
          import hashlib
          import os
          import sqlite3
          import urllib.parse
          import urllib.request
          from datetime import datetime, timezone
          from pathlib import Path

          from reportlab.lib.pagesizes import A4
          from reportlab.pdfgen import canvas

          csv_path = Path(os.environ["TARGET_CSV"])
          pdf_path = Path(os.environ["TARGET_PDF"])
          sha_path = Path(os.environ["TARGET_SHA"])

          filters = {
              "site_id": (os.environ.get("FILTER_SITE_ID") or "").strip(),
              "sync_id": (os.environ.get("FILTER_SYNC_ID") or "").strip(),
              "subject_id": (os.environ.get("FILTER_SUBJECT_ID") or "").strip(),
              "operator_id": (os.environ.get("FILTER_OPERATOR_ID") or "").strip(),
              "platform": (os.environ.get("FILTER_PLATFORM") or "").strip(),
              "capture_mode": (os.environ.get("FILTER_CAPTURE_MODE") or "").strip(),
              "quality_status": (os.environ.get("FILTER_QUALITY_STATUS") or "all").strip().lower() or "all",
          }

          def _norm(value: object) -> str:
              return str(value if value is not None else "").strip()

          def _to_int(value: object) -> int | None:
              text = _norm(value)
              if not text:
                  return None
              try:
                  return int(float(text))
              except ValueError:
                  return None

          def _filter_paired(row: dict[str, object]) -> bool:
              if filters["site_id"] and _norm(row.get("site_id")) != filters["site_id"]:
                  return False
              if filters["sync_id"] and _norm(row.get("sync_id")) != filters["sync_id"]:
                  return False
              if filters["subject_id"] and _norm(row.get("subject_id")) != filters["subject_id"]:
                  return False
              if filters["operator_id"] and _norm(row.get("operator_id")) != filters["operator_id"]:
                  return False
              if filters["platform"] and _norm(row.get("platform")) != filters["platform"]:
                  return False
              if filters["capture_mode"] and _norm(row.get("capture_mode")) != filters["capture_mode"]:
                  return False
              if filters["quality_status"] != "all":
                  if _norm(row.get("app_quality_status")).lower() != filters["quality_status"]:
                      return False
              return True

          def _filter_capture(row: dict[str, object]) -> bool:
              if filters["site_id"] and _norm(row.get("site_id")) != filters["site_id"]:
                  return False
              if filters["sync_id"] and _norm(row.get("sync_id")) != filters["sync_id"]:
                  return False
              if filters["subject_id"] and _norm(row.get("subject_id")) != filters["subject_id"]:
                  return False
              if filters["operator_id"] and _norm(row.get("operator_id")) != filters["operator_id"]:
                  return False
              if filters["platform"] and _norm(row.get("platform")) != filters["platform"]:
                  return False
              if filters["capture_mode"] and _norm(row.get("capture_mode")) != filters["capture_mode"]:
                  return False
              return True

          def _load_rows_from_api() -> tuple[list[dict[str, object]], list[dict[str, object]]]:
              base_url = (os.environ.get("SOURCE_API_BASE_URL") or "").rstrip("/")
              if not base_url:
                  raise RuntimeError("SOURCE_API_BASE_URL is empty while source_mode=api")

              headers: dict[str, str] = {}
              api_key = (os.environ.get("SOURCE_API_KEY") or "").strip()
              if api_key:
                  headers["x-api-key"] = api_key

              server_query: dict[str, str] = {}
              for key in ("site_id", "sync_id", "operator_id"):
                  value = filters.get(key, "")
                  if value:
                      server_query[key] = value

              def _fetch_csv(path: str) -> list[dict[str, object]]:
                  query = urllib.parse.urlencode(server_query)
                  url = f"{base_url}{path}"
                  if query:
                      url = f"{url}?{query}"
                  request = urllib.request.Request(url, headers=headers)
                  with urllib.request.urlopen(request, timeout=30) as response:
                      payload = response.read().decode("utf-8")
                  return [dict(row) for row in csv.DictReader(payload.splitlines())]

              paired_rows = [row for row in _fetch_csv("/api/v1/paired-measurements.csv") if _filter_paired(row)]
              capture_rows = [row for row in _fetch_csv("/api/v1/capture-packages.csv") if _filter_capture(row)]
              return paired_rows, capture_rows

          def _load_rows_from_db() -> tuple[list[dict[str, object]], list[dict[str, object]]]:
              db_path = Path(os.environ["SOURCE_DB_PATH"])
              if not db_path.exists():
                  raise FileNotFoundError(f"db path not found: {db_path}")

              with sqlite3.connect(db_path) as connection:
                  connection.row_factory = sqlite3.Row
                  paired_rows = [
                      dict(row)
                      for row in connection.execute(
                          """
                          SELECT
                              id,
                              session_id,
                              sync_id,
                              site_id,
                              subject_id,
                              operator_id,
                              attempt_number,
                              platform,
                              capture_mode,
                              app_quality_status
                          FROM paired_measurements
                          """
                      )
                  ]
                  capture_rows = [
                      dict(row)
                      for row in connection.execute(
                          """
                          SELECT
                              id,
                              session_id,
                              sync_id,
                              site_id,
                              subject_id,
                              operator_id,
                              attempt_number,
                              platform,
                              capture_mode,
                              paired_measurement_id
                          FROM capture_packages
                          """
                      )
                  ]

              paired_rows = [row for row in paired_rows if _filter_paired(row)]
              capture_rows = [row for row in capture_rows if _filter_capture(row)]
              return paired_rows, capture_rows

          source_mode = (os.environ.get("SOURCE_MODE") or "").strip().lower()
          if source_mode == "api":
              paired_rows, capture_rows = _load_rows_from_api()
          elif source_mode == "db":
              paired_rows, capture_rows = _load_rows_from_db()
          else:
              raise ValueError(f"Unsupported SOURCE_MODE: {source_mode!r}")

          capture_by_pair_id: set[int] = set()
          capture_by_identity: set[tuple[str, int, str, str, str]] = set()

          for row in capture_rows:
              paired_measurement_id = _to_int(row.get("paired_measurement_id"))
              if paired_measurement_id is not None:
                  capture_by_pair_id.add(paired_measurement_id)

              identity = (
                  _norm(row.get("session_id")),
                  _to_int(row.get("attempt_number")) or 0,
                  _norm(row.get("site_id")),
                  _norm(row.get("subject_id")),
                  _norm(row.get("sync_id")),
              )
              capture_by_identity.add(identity)

          quality_distribution = {"valid": 0, "repeat": 0, "reject": 0}
          match_distribution = {"paired_id": 0, "session_identity": 0, "none": 0}

          for row in paired_rows:
              quality_status = _norm(row.get("app_quality_status")).lower()
              if quality_status in quality_distribution:
                  quality_distribution[quality_status] += 1

              paired_id = _to_int(row.get("id")) or 0
              identity = (
                  _norm(row.get("session_id")),
                  _to_int(row.get("attempt_number")) or 0,
                  _norm(row.get("site_id")),
                  _norm(row.get("subject_id")),
                  _norm(row.get("sync_id")),
              )

              if paired_id in capture_by_pair_id:
                  match_distribution["paired_id"] += 1
              elif identity in capture_by_identity:
                  match_distribution["session_identity"] += 1
              else:
                  match_distribution["none"] += 1

          paired_total = len(paired_rows)
          paired_without_capture = match_distribution["none"]
          paired_with_capture = paired_total - paired_without_capture
          coverage_ratio = (paired_with_capture / paired_total) if paired_total > 0 else 0.0

          summary_row = {
              "generated_at": datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z"),
              "site_id": filters["site_id"],
              "sync_id": filters["sync_id"],
              "subject_id": filters["subject_id"],
              "operator_id": filters["operator_id"],
              "platform": filters["platform"],
              "capture_mode": filters["capture_mode"],
              "quality_status": filters["quality_status"],
              "paired_total": paired_total,
              "paired_with_capture": paired_with_capture,
              "paired_without_capture": paired_without_capture,
              "coverage_ratio": f"{coverage_ratio:.6f}",
              "quality_valid": quality_distribution["valid"],
              "quality_repeat": quality_distribution["repeat"],
              "quality_reject": quality_distribution["reject"],
              "match_paired_id": match_distribution["paired_id"],
              "match_session_identity": match_distribution["session_identity"],
              "match_none": match_distribution["none"],
          }

          csv_path.parent.mkdir(parents=True, exist_ok=True)
          with csv_path.open("w", encoding="utf-8", newline="") as handle:
              writer = csv.DictWriter(
                  handle,
                  fieldnames=[
                      "generated_at",
                      "site_id",
                      "sync_id",
                      "subject_id",
                      "operator_id",
                      "platform",
                      "capture_mode",
                      "quality_status",
                      "paired_total",
                      "paired_with_capture",
                      "paired_without_capture",
                      "coverage_ratio",
                      "quality_valid",
                      "quality_repeat",
                      "quality_reject",
                      "match_paired_id",
                      "match_session_identity",
                      "match_none",
                  ],
              )
              writer.writeheader()
              writer.writerow(summary_row)

          payload = csv_path.read_bytes()
          sha_path.write_text(
              f"{hashlib.sha256(payload).hexdigest()}  {csv_path.name}\n",
              encoding="utf-8",
          )

          pdf_path.parent.mkdir(parents=True, exist_ok=True)
          sheet = canvas.Canvas(str(pdf_path), pagesize=A4)
          _, height = A4
          y = [height - 42]

          def line(text: str, step: int = 16) -> None:
              sheet.drawString(42, y[0], text)
              y[0] -= step

          line("Capture Coverage Summary")
          line(f"Generated at: {summary_row['generated_at']}")
          line(f"Site: {summary_row['site_id'] or '-'}")
          line(f"Sync ID: {summary_row['sync_id'] or '-'}")
          line(f"Quality status: {summary_row['quality_status']}")
          y[0] -= 6
          line(
              f"Paired total: {summary_row['paired_total']}, "
              f"with capture: {summary_row['paired_with_capture']}, "
              f"without capture: {summary_row['paired_without_capture']}"
          )
          line(f"Coverage ratio: {float(summary_row['coverage_ratio']) * 100:.1f}%")
          line(
              "Quality distribution: "
              f"valid={summary_row['quality_valid']}, "
              f"repeat={summary_row['quality_repeat']}, "
              f"reject={summary_row['quality_reject']}"
          )
          line(
              "Match modes: "
              f"paired_id={summary_row['match_paired_id']}, "
              f"session_identity={summary_row['match_session_identity']}, "
              f"none={summary_row['match_none']}"
          )
          sheet.showPage()
          sheet.save()
          PY

          echo "report_dir=$report_dir" >> "$GITHUB_OUTPUT"
          echo "csv_path=$csv_path" >> "$GITHUB_OUTPUT"
        env:
          SOURCE_MODE: ${{ steps.source.outputs.source_mode }}
          SOURCE_DB_PATH: ${{ steps.source.outputs.db_path }}
          SOURCE_API_BASE_URL: ${{ steps.source.outputs.api_base_url }}
          SOURCE_API_KEY: ${{ secrets.CLINICAL_HUB_API_KEY }}
          FILTER_SITE_ID: ${{ steps.filters.outputs.site_id }}
          FILTER_SYNC_ID: ${{ steps.filters.outputs.sync_id }}
          FILTER_SUBJECT_ID: ${{ steps.filters.outputs.subject_id }}
          FILTER_OPERATOR_ID: ${{ steps.filters.outputs.operator_id }}
          FILTER_PLATFORM: ${{ steps.filters.outputs.platform }}
          FILTER_CAPTURE_MODE: ${{ steps.filters.outputs.capture_mode }}
          FILTER_QUALITY_STATUS: ${{ steps.filters.outputs.quality_status }}

      - name: Evaluate coverage gates
        id: gates
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import csv
          import json
          import math
          import os
          from pathlib import Path

          csv_path = Path("${{ steps.generate.outputs.csv_path }}")
          report_dir = Path("${{ steps.generate.outputs.report_dir }}")
          config_path = Path("${{ steps.filters.outputs.targets_config }}")
          output_path = report_dir / "coverage_gates.json"

          if not csv_path.exists():
              raise FileNotFoundError(f"coverage csv not found: {csv_path}")
          if not config_path.exists():
              raise FileNotFoundError(f"targets config not found: {config_path}")

          with csv_path.open("r", encoding="utf-8", newline="") as handle:
              rows = list(csv.DictReader(handle))
          row = rows[0] if rows else {}

          paired_total = float(row.get("paired_total", "0") or "0")
          denominator = paired_total if paired_total > 0 else 1.0
          quality_valid = float(row.get("quality_valid", "0") or "0")
          quality_repeat = float(row.get("quality_repeat", "0") or "0")
          quality_reject = float(row.get("quality_reject", "0") or "0")
          match_none = float(row.get("match_none", "0") or "0")

          metrics = {
              "paired_total": paired_total,
              "paired_with_capture": float(row.get("paired_with_capture", "0") or "0"),
              "paired_without_capture": float(row.get("paired_without_capture", "0") or "0"),
              "coverage_ratio": float(row.get("coverage_ratio", "0") or "0"),
              "quality_valid_count": quality_valid,
              "quality_repeat_count": quality_repeat,
              "quality_reject_count": quality_reject,
              "quality_valid_ratio": quality_valid / denominator,
              "quality_repeat_ratio": quality_repeat / denominator,
              "quality_reject_ratio": quality_reject / denominator,
              "capture_match_none_count": match_none,
              "capture_match_none_ratio": match_none / denominator,
          }

          config_payload = json.loads(config_path.read_text(encoding="utf-8"))
          if not isinstance(config_payload, dict):
              raise ValueError("coverage targets config must be a JSON object")
          gates = config_payload.get("gates")
          if not isinstance(gates, list) or len(gates) == 0:
              raise ValueError("coverage targets config must include non-empty 'gates' list")

          def evaluate(actual: float, operator: str, threshold: float) -> bool:
              if operator == ">=":
                  return actual >= threshold
              if operator == ">":
                  return actual > threshold
              if operator == "<=":
                  return actual <= threshold
              if operator == "<":
                  return actual < threshold
              if operator == "==":
                  return actual == threshold
              raise ValueError(f"Unsupported gate operator: {operator}")

          evaluations = []
          hard_passed = True
          warning_passed = True
          for index, gate in enumerate(gates):
              if not isinstance(gate, dict):
                  raise ValueError(f"gates[{index}] must be object")
              metric = gate.get("metric")
              operator = gate.get("operator")
              threshold = gate.get("threshold")
              if not isinstance(metric, str) or metric not in metrics:
                  raise ValueError(f"gates[{index}].metric is invalid: {metric!r}")
              if not isinstance(operator, str) or operator not in {">=", ">", "<=", "<", "=="}:
                  raise ValueError(f"gates[{index}].operator is invalid: {operator!r}")
              if not isinstance(threshold, (int, float)) or not math.isfinite(float(threshold)):
                  raise ValueError(f"gates[{index}].threshold must be finite number")
              severity = str(gate.get("severity", "hard")).strip().lower()
              if severity not in {"hard", "warning"}:
                  raise ValueError(f"gates[{index}].severity must be 'hard' or 'warning'")
              actual = float(metrics[metric])
              passed = evaluate(actual, operator, float(threshold))
              if severity == "hard" and not passed:
                  hard_passed = False
              if severity == "warning" and not passed:
                  warning_passed = False
              evaluations.append(
                  {
                      "id": gate.get("id") or metric,
                      "label": gate.get("label") or metric,
                      "metric": metric,
                      "operator": operator,
                      "threshold": float(threshold),
                      "actual": actual,
                      "severity": severity,
                      "passed": passed,
                  }
              )

          report = {
              "config_path": str(config_path),
              "config_version": config_payload.get("version"),
              "config_name": config_payload.get("name"),
              "metrics": metrics,
              "gates": evaluations,
              "hard_passed": hard_passed,
              "warning_passed": warning_passed,
              "overall_passed": hard_passed,
          }
          output_path.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
          with Path(os.environ["GITHUB_OUTPUT"]).open("a", encoding="utf-8") as handle:
              handle.write(f"gates_json_path={output_path}\n")
              handle.write(f"hard_passed={'true' if hard_passed else 'false'}\n")
              handle.write(f"warning_passed={'true' if warning_passed else 'false'}\n")
          print(f"Coverage gates report saved: {output_path}")
          print(f"hard_passed={hard_passed}, warning_passed={warning_passed}")
          PY

      - name: Upload coverage report artifact
        uses: actions/upload-artifact@v4
        with:
          name: capture-coverage-report-${{ github.run_id }}
          path: ${{ steps.generate.outputs.report_dir }}
          if-no-files-found: error

      - name: Enforce hard coverage gates
        if: ${{ steps.filters.outputs.enforce_coverage_gates == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          if [[ "${{ steps.gates.outputs.hard_passed }}" != "true" ]]; then
            echo "Hard coverage gates failed."
            exit 1
          fi
          echo "Hard coverage gates passed."

      - name: Publish workflow summary
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import csv
          import os
          from pathlib import Path

          csv_path = Path("${{ steps.generate.outputs.csv_path }}")
          with csv_path.open("r", encoding="utf-8", newline="") as handle:
              rows = list(csv.DictReader(handle))
          row = rows[0] if rows else {}

          paired_total = int(row.get("paired_total", "0") or "0")
          paired_with_capture = int(row.get("paired_with_capture", "0") or "0")
          coverage_ratio = float(row.get("coverage_ratio", "0") or "0")
          hard_passed = "${{ steps.gates.outputs.hard_passed }}" or "false"
          warning_passed = "${{ steps.gates.outputs.warning_passed }}" or "false"
          enforce_hard = "${{ steps.filters.outputs.enforce_coverage_gates }}" or "false"
          gates_path = "${{ steps.gates.outputs.gates_json_path }}" or "-"
          targets_config = "${{ steps.filters.outputs.targets_config }}" or "-"

          summary_lines = [
              "## Capture Coverage Summary",
              f"- Source mode: `${{ steps.source.outputs.source_mode }}`",
              f"- Paired total: `{paired_total}`",
              f"- Paired with capture: `{paired_with_capture}`",
              f"- Coverage ratio: `{coverage_ratio * 100:.1f}%`",
              f"- Site: `{row.get('site_id', '') or '-'}`",
              f"- Sync: `{row.get('sync_id', '') or '-'}`",
              f"- Quality filter: `{row.get('quality_status', '') or 'all'}`",
              f"- Targets config: `{targets_config}`",
              f"- Hard gates passed: `{hard_passed}`",
              f"- Warning gates passed: `{warning_passed}`",
              f"- Hard gate enforcement: `{enforce_hard}`",
              f"- Gates report: `{gates_path}`",
          ]
          Path(os.environ["GITHUB_STEP_SUMMARY"]).write_text(
              "\n".join(summary_lines) + "\n",
              encoding="utf-8",
          )
          PY
